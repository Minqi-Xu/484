{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bcc9063",
   "metadata": {},
   "source": [
    "# Final Project\n",
    "# Topic 4: High-dynamic range imaging. (Debevec-Malik method)\n",
    "\n",
    "All contents written by Minqi Xu.\n",
    "\n",
    "email: m259xu@uwaterloo.ca"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e839262e",
   "metadata": {},
   "source": [
    "The reason I choose this topic as the final profect topic is that I am interested in photography, and I notice that on recently device, there is a function called HDR. I have briefly inquired about the principle, and it seems to be to take multiple photos with different exposures and then perform algorithmic synthesis. So when I saw this topic, I immediately get interested in it. Also, I saw that the difficulty of this topic is a single plus, which is suitable for me to complete the project alone, so I chose it without hesitation.\n",
    "\n",
    "The goal of this project is to implement the Debevec-Malik method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e462479a",
   "metadata": {},
   "source": [
    "Note that cv2 is imported, and it is not installed with the default anaconda package. The way to install it is type \"pip install opencv-python\" in terminal.\n",
    "\n",
    "numpy is imported since we are going to use np.ndarray to store images.\n",
    "\n",
    "matplotlib.pyplot is imported to display plots.\n",
    "\n",
    "matplotlib.image is imported to load and display images.\n",
    "\n",
    "random is imported to randomly select sample pixel.\n",
    "\n",
    "cv2(openCV) is imported since we need to apply a non-linear bilateral filter during tone mapping. Also the normalize is used.\n",
    "\n",
    "nupy.linalg is imported to calculate the inverse of matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c480a71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as image\n",
    "import random\n",
    "from numpy import linalg as la\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39dea67d",
   "metadata": {},
   "source": [
    "We need to read the image and exposure time first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ccfd3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_info():\n",
    "    # channel: the channel that we want, range = {0,1,2}\n",
    "    img_list = []\n",
    "    img_list.append(image.imread(\"image/blimp1.jpg\"))\n",
    "    img_list.append(image.imread(\"image/blimp2.jpg\"))\n",
    "    img_list.append(image.imread(\"image/blimp3.jpg\"))\n",
    "    \n",
    "    exposure_times = np.array([1/2048, 1/1024, 1/512], dtype=float)\n",
    "    return (img_list, exposure_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a61557d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sample(img_list):\n",
    "    # randomly sample pixel intensity\n",
    "    # img_list: list[np.ndarray], a list contains image of single channel\n",
    "    \n",
    "    img_num = len(img_list)\n",
    "    z_min = 0\n",
    "    z_max = 255\n",
    "    i_num = z_max - z_min + 1\n",
    "    i_value = np.zeros((i_num, img_num), dtype=np.uint8)\n",
    "    \n",
    "    temp_img = img_list[img_num//2]\n",
    "    \n",
    "    for i in range(z_min, z_max+1):\n",
    "        x,y = np.where(temp_img == i)\n",
    "        if len(x) > 0:\n",
    "            rand_num = random.randrange(len(x))\n",
    "            for j in range(img_num):\n",
    "                i_value[i][j] = img_list[j][x[rand_num]][y[rand_num]]\n",
    "    return i_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8564fb",
   "metadata": {},
   "source": [
    "Following there step, we move to stage 1: Estimate the radiometric response function from the aligned images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b5c9e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_func(value):\n",
    "    z_min = 0.0\n",
    "    z_max = 255.0\n",
    "    if value <= (z_min + z_max) / 2:\n",
    "        return value - z_min\n",
    "    return z_max - value\n",
    "\n",
    "def recover_response_curve(lambdaa, log_e, sample):\n",
    "    # lambdaa is the smoothing variable\n",
    "    # log_e: np.ndarray, is the log of the exposure times\n",
    "    # sample: np.ndarray, Single channel input of values\n",
    "    \n",
    "    i_range = 255  # intensity_range\n",
    "    sample_num = sample.shape[0]\n",
    "    image_num = len(log_e)\n",
    "    \n",
    "    A = np.zeros((image_num * sample_num + i_range, sample_num + i_range + 1), dtype=float)\n",
    "    B = np.zeros((A.shape[0], 1), dtype=float)\n",
    "    \n",
    "    # add the data-fitting:\n",
    "    k = 0\n",
    "    for i in range(sample_num):\n",
    "        for j in range(image_num):\n",
    "            z = sample[i][j]\n",
    "            w = weight_func(z)\n",
    "            A[k][z] = w\n",
    "            A[k][i_range+1+i] = -w\n",
    "            B[k][0] = w * log_e[j]\n",
    "            k = k+1\n",
    "    \n",
    "    # add the smoothing:\n",
    "    for z in range(1, 255):\n",
    "        w = weight_func(z)\n",
    "        A[k][z-1] = lambdaa * w\n",
    "        A[k][z] = -2 * lambdaa * w\n",
    "        A[k][z+1] = lambdaa * w\n",
    "        k = k + 1\n",
    "    \n",
    "    # set middle to 0\n",
    "    A[k][255//2] = 1\n",
    "    \n",
    "    \n",
    "    A_inv = np.linalg.pinv(A)\n",
    "    temp = np.matmul(A_inv, B)\n",
    "    \n",
    "    g = temp[0: i_range+1]\n",
    "    return g[:,0]\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bd8d15",
   "metadata": {},
   "source": [
    "After the first stage, we are moving to the second stage, which is estimate a radiance map by selecting or blending pixels from different exposures. We need to merge the input images into a composite radiance map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "388fdb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRadianceMap(img_list, log_e, response):\n",
    "    # img_list: list[np.ndarray], a list contains image of single channel\n",
    "    # log_e: np.ndarray, log exposure times\n",
    "    # response: np.ndarray, response curve\n",
    "    \n",
    "    img_shape = img_list[0].shape\n",
    "    rad = np.zeros(img_shape, dtype=float)\n",
    "    \n",
    "    img_num = len(img_list)\n",
    "    \n",
    "    for i in range(img_shape[0]):\n",
    "        for j in range(img_shape[1]):\n",
    "            g = np.array([response[img_list[k][i][j]] for k in range(img_num)])\n",
    "            w = np.array([(img_list[z][i][j] if img_list[z][i][j] <= (255.0/2.0) else (255-img_list[z][i][j])) \\\n",
    "                                                                          for z in range(img_num)])\n",
    "            tot = np.sum(w)\n",
    "            if tot>0:\n",
    "                rad[i][j] = np.sum(w * (g - log_e) / tot)\n",
    "            else:\n",
    "                rad[i][j] = g[img_num // 2] - log_e[img_num // 2]\n",
    "                #rad[i][j] = np.sum(w * (g - log_e))\n",
    "    \n",
    "    return rad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8893a229",
   "metadata": {},
   "source": [
    "After calculate the radiance map, we are now moving to the third stage, which is tone map the resulting high dynamic range (HDR) iamge back into a displayable gamut. Following, we are going to use the Durand's method of local tone mapping using a bilateral filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c53d27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def toneMap(img, gamma=0.6, sigma_space=4, sigma_color=4):\n",
    "    # img: np.ndarray, image needed to be correct\n",
    "    \n",
    "    \n",
    "    # get Luminance of img\n",
    "    img_intensity = np.average(img, axis=2, weights=[0.2126, 0.7152, 0.0722]) # this data comes from internet\n",
    "    \n",
    "    # compute the chrominance channels\n",
    "    R = img[:,:,0]/img_intensity\n",
    "    G = img[:,:,1]/img_intensity\n",
    "    B = img[:,:,2]/img_intensity\n",
    "    \n",
    "    # compute the log of the intensity\n",
    "    L = np.log2(img_intensity)\n",
    "    \n",
    "    # apply bilateral filter\n",
    "    L = np.float32(L)\n",
    "    blur = cv2.bilateralFilter(L, d=3, sigmaColor=sigma_color, sigmaSpace=sigma_space)\n",
    "    \n",
    "    # compute the detail layer\n",
    "    detail_layer = L - blur\n",
    "    \n",
    "    # apply offset and scale to base\n",
    "    offset = np.max(blur)\n",
    "    scale = 6 / (np.max(blur) - np.min(blur))\n",
    "    base = (blur - offset) * scale\n",
    "    \n",
    "    # reconstruct log intensity\n",
    "    log_i_reconstruct = np.zeros_like(blur)\n",
    "    log_i_reconstruct.fill(2)\n",
    "    log_i_reconstruct = np.power(log_i_reconstruct, (blur + detail_layer))\n",
    "    \n",
    "    # reconstruct colors\n",
    "    R_re = log_i_reconstruct * R\n",
    "    G_re = log_i_reconstruct * G\n",
    "    B_re = log_i_reconstruct * B\n",
    "    \n",
    "    newimg = img.copy()\n",
    "    newimg[:,:,0]=R_re\n",
    "    newimg[:,:,1]=G_re\n",
    "    newimg[:,:,2]=B_re\n",
    "    \n",
    "    newimg = newimg.astype('float32')/255\n",
    "    \n",
    "    # apply gamma correction\n",
    "    newimg = np.power(newimg, 1/gamma)\n",
    "    \n",
    "    plt.figure(figsize = (12, 8))\n",
    "    plt.subplot(231)\n",
    "    plt.title('image of base')\n",
    "    plt.imshow(blur)\n",
    "    plt.subplot(232)\n",
    "    plt.title('image of detail layer')\n",
    "    plt.imshow(detail_layer)\n",
    "    plt.subplot(233)\n",
    "    plt.title('image of log\\(intensity\\) reconstruction')\n",
    "    plt.imshow(log_i_reconstruct)\n",
    "    plt.subplot(234)\n",
    "    plt.title('image after tone mapping')\n",
    "    plt.imshow(newimg)\n",
    "    plt.subplot(235)\n",
    "    plt.title('intensity')\n",
    "    plt.imshow(img_intensity)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    return newimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d125e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHDR(img_list, log_e, lambdaa=100):\n",
    "    # img_list: list[np.ndarray], list of images\n",
    "    # log_e: np.ndarray: log of exposure times for images\n",
    "    \n",
    "    image_shape = img_list[0].shape\n",
    "    channel_num = img_list[0].shape[2]\n",
    "    hdr_img = np.zeros(image_shape, dtype=float)\n",
    "    \n",
    "    for i in range(channel_num):\n",
    "        # split the channels\n",
    "        single_channel = [img[:,:,i] for img in img_list]\n",
    "        \n",
    "        # get the sample intensity\n",
    "        sample = create_sample(single_channel)\n",
    "        \n",
    "        # calculate response curve\n",
    "        response_curve = recover_response_curve(lambdaa, log_e, sample)\n",
    "        \n",
    "        # create radiance map\n",
    "        rad_map = getRadianceMap(single_channel, log_e, response_curve)\n",
    "        \n",
    "        # get the hdr img, and normalize it to (0,255)\n",
    "        hdr_img[:,:,i] = cv2.normalize(rad_map, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX)\n",
    "        \n",
    "    hdr_img = np.float32(hdr_img)\n",
    "    # applying tone mapping\n",
    "    map_img = toneMap(hdr_img)\n",
    "    \n",
    "    return map_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29defd70",
   "metadata": {},
   "source": [
    "After this, we obtained a raw HDR image, we still need to Adjust the intensity of each channel of this image. We can choose our target intensity as the same as middle image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87108bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intensityCorrection(rawHDR, target):\n",
    "    # rawHDR: np.ndarray, raw HDR image that need to be correct\n",
    "    # target: np.ndarray, the target intensity that tempHDR need to be corrected\n",
    "    \n",
    "    finalHDR = np.zeros_like(rawHDR)\n",
    "    for i in range(rawHDR.shape[2]):\n",
    "        rawVal = np.average(rawHDR[:,:,i])\n",
    "        targetVal = np.average(target[:,:,i])\n",
    "        finalHDR[:,:,i] = rawHDR[:,:,i] * targetVal / rawVal\n",
    "    \n",
    "    # normalize the finalHDR\n",
    "    finalHDR = cv2.normalize(finalHDR, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX)\n",
    "    \n",
    "    return finalHDR.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cec25b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list, exposure_time = get_img_info()\n",
    "log_e = np.log2(exposure_time)\n",
    "\n",
    "HDR_img = getHDR(img_list, log_e)\n",
    "\n",
    "# need to correct the intensity\n",
    "target = img_list[len(img_list)//2]\n",
    "finalHDR = intensityCorrection(HDR_img, target)\n",
    "\n",
    "plt.figure(figsize = (12, 10))\n",
    "plt.subplot(231)\n",
    "plt.title('Original image 1')\n",
    "plt.imshow(img_list[0])\n",
    "plt.subplot(232)\n",
    "plt.title('Original image 2')\n",
    "plt.imshow(img_list[1])\n",
    "plt.subplot(233)\n",
    "plt.title('Original image 3')\n",
    "plt.imshow(img_list[2])\n",
    "plt.subplot(234)\n",
    "plt.title('HDR image')\n",
    "plt.imshow(finalHDR)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1d399c",
   "metadata": {},
   "source": [
    "In the previous cell, the last image is the HDR we obtained, although it is not that good, but compared to the second original image, the ground is slightly lighter, and the sun is darker."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeae3393",
   "metadata": {},
   "source": [
    "Here are two more examples from https://www.easyhdr.com/examples/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd93576c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list = []\n",
    "img_list.append(image.imread(\"image/cannon1.jpg\"))\n",
    "img_list.append(image.imread(\"image/cannon2.jpg\"))\n",
    "img_list.append(image.imread(\"image/cannon3.jpg\"))\n",
    "    \n",
    "exposure_times = np.array([1/2048, 1/1024, 1/512], dtype=float)\n",
    "log_e = np.log2(exposure_times)\n",
    "\n",
    "HDR_img = getHDR(img_list, log_e)\n",
    "\n",
    "# need to correct the intensity\n",
    "target = img_list[len(img_list)//2]\n",
    "finalHDR = intensityCorrection(HDR_img, target)\n",
    "\n",
    "plt.figure(figsize = (12, 10))\n",
    "plt.subplot(231)\n",
    "plt.title('Original image 1')\n",
    "plt.imshow(img_list[0])\n",
    "plt.subplot(232)\n",
    "plt.title('Original image 2')\n",
    "plt.imshow(img_list[1])\n",
    "plt.subplot(233)\n",
    "plt.title('Original image 3')\n",
    "plt.imshow(img_list[2])\n",
    "plt.subplot(234)\n",
    "plt.title('HDR image')\n",
    "plt.imshow(finalHDR)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935b1aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list = []\n",
    "img_list.append(image.imread(\"image/cap-de-formentor1.jpg\"))\n",
    "img_list.append(image.imread(\"image/cap-de-formentor2.jpg\"))\n",
    "img_list.append(image.imread(\"image/cap-de-formentor3.jpg\"))\n",
    "    \n",
    "exposure_times = np.array([1/2048, 1/1024, 1/512], dtype=float)\n",
    "log_e = np.log2(exposure_times)\n",
    "\n",
    "HDR_img = getHDR(img_list, log_e)\n",
    "\n",
    "# need to correct the intensity\n",
    "target = img_list[len(img_list)//2]\n",
    "finalHDR = intensityCorrection(HDR_img, target)\n",
    "\n",
    "plt.figure(figsize = (12, 10))\n",
    "plt.subplot(231)\n",
    "plt.title('Original image 1')\n",
    "plt.imshow(img_list[0])\n",
    "plt.subplot(232)\n",
    "plt.title('Original image 2')\n",
    "plt.imshow(img_list[1])\n",
    "plt.subplot(233)\n",
    "plt.title('Original image 3')\n",
    "plt.imshow(img_list[2])\n",
    "plt.subplot(234)\n",
    "plt.title('HDR image')\n",
    "plt.imshow(finalHDR)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453dc1c4",
   "metadata": {},
   "source": [
    "In these examples, especially the second one where there is a cannon. It is obviously that the HDR image gathering the information from three original images well without over- or under-exposure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a288b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
